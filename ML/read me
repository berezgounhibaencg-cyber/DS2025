import pandas as pd
import numpy as np
link = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
df = pd.read_csv(link, header="infer", delimiter=";")

print("\n========= Dataset summary ========= \n")
df.info()
print("\n========= A few first samples ========= \n")
print(df.head())
X = df.drop("quality", axis=1) # On enlève la colonne "quality"
Y = df["quality"]

print("\n========= Wine Qualities (Original) ========= \n")
print(Y.value_counts())
# mauvais vin (y=0) : quality <= 5 et bon vin (y= 1) sinon
Y = [0 if val <=5 else 1 for val in Y]
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure()
ax = plt.gca()
sns.boxplot(data=X,orient="v",palette="Set1",width=1.5, notch=True)
ax.set_xticklabels(ax.get_xticklabels(),rotation=90)
plt.figure()
corr = X.corr()
sns.heatmap(corr)
from sklearn.model_selection import train_test_split

# 1. Division en (Xa, Ya) pour l'entraînement/validation et (Xt, Yt) pour le test (1/3 des données)
Xa, Xt, Ya, Yt = train_test_split(X, Y, shuffle=True, test_size=1/3, stratify=Y)

# 2. Division de (Xa, Ya) en ensembles d'entraînement (Xa, Ya) et de validation (Xv, Yv) (50% de l'ensemble restant)
Xa, Xv, Ya, Yv = train_test_split(Xa, Ya, shuffle=True, test_size=0.5, stratify=Ya)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Entraînement avec k=3
k = 3
clf = KNeighborsClassifier(n_neighbors = k)
clf.fit(Xa, Ya)

# Prédiction sur l'ensemble de validation
Ypred_v = clf.predict(Xv)

# Calcul de l'erreur de classification (1 - précision)
error_v = 1-accuracy_score(Yv, Ypred_v)
print(f"\nErreur de classification sur la validation pour k={k}: {error_v:.4f}\n")
k_vector = np.arange(1, 37, 2) # k=1, 3, 5, ...
error_train = np.empty(k_vector.shape)
error_val = np.empty(k_vector.shape)

for ind, k in enumerate(k_vector):
    # Entraînement du modèle avec k
    clf = KNeighborsClassifier(n_neighbors = k)
    clf.fit(Xa, Ya)

    # Prédiction et évaluation sur les ensembles d'entraînement et de validation
    Ypred_train = clf.predict(Xa)
    error_train[ind] = 1 - accuracy_score(Ya, Ypred_train)

    Ypred_val = clf.predict(Xv)
    error_val[ind] = 1 - accuracy_score(Yv, Ypred_val)
err_min, ind_opt = error_val.min(), error_val.argmin()
k_star = k_vector[ind_opt]

print(f"L'erreur minimale de validation est: {err_min:.4f}")
print(f"Le k* optimal est: {k_star}")
